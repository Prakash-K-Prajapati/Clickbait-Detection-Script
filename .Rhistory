install.packages(c("tm", "SnowballC", "caret", "e1071", "ggplot2"))
library(tm)
library(SnowballC)
library(caret)
library(e1071)
library(ggplot2)
library(tm)
library(SnowballC)
library(caret)
library(e1071)
library(ggplot2)
library(tm)
library(SnowballC)
library(caret)
library(e1071)
library(ggplot2)
library(ggplot2)
data <- read.csv("C:/Users/YourUsername/Desktop/clickbait_data.csv")
data <- read.csv("C:/Users/YourUsername/Desktop/clickbait_data.csv")
data <- read.csv("C:/Users/YourUsername/Desktop/clickbait_data.csv")
data <- read.csv("C:/Users/Prakash Kumar/Downloads/clickbait_data(1).csv")
data <- read.csv("C:/Users/'Prakash Kumar'/Downloads/clickbait_data(1).csv")
file.exists("C:/Users/Prakash Kumar/Downloads/clickbait_data(1).csv")
file.exists("C:/Users/Prakash Kumar/Downloads/clickbait_data(1).csv")
data <- read.csv(file.choose())
data <- read.csv(file.choose()fill = TRUE)
data <- read.csv(file.choose(),fill = TRUE)
library(readr)
install.package(readr)
install.packages(readr)
install.packages(c("readr"))
library(readr)
data <- read_csv(file.choose(),fill = TRUE,skipNUL = TRUE)
data <- read_csv(file.choose(),fill = TRUE,skipNul = TRUE)
data <- read_csv(file.choose())
data <- read_csv(file.choose(),skipNul = TRUE)
data <- read_csv(file.choose())
dat <- vroom(...)
problems(dat)
problems()
head(data)
corpus <- Corpus(VectorSource(data$Text))  # Convert the text into a "corpus" (an R object for text data)
corpus <- tm_map(corpus, content_transformer(tolower))  # Convert all text to lowercase
corpus <- tm_map(corpus, removePunctuation)  # Remove punctuation
corpus <- tm_map(corpus, removeNumbers)  # Remove numbers
corpus <- tm_map(corpus, removeWords, stopwords("en"))  # Remove common words like "the", "and", etc.
corpus <- tm_map(corpus, stripWhitespace)  # Remove extra whitespace
colnames(data)
corpus <- Corpus(VectorSource(data$headline))  # Convert the text into a "corpus" (an R object for text data)
corpus <- Corpus(VectorSource(data$clickbait))  # Convert the text into a "corpus" (an R object for text data)
corpus <- tm_map(corpus, content_transformer(tolower))  # Convert all text to lowercase
corpus <- tm_map(corpus, removePunctuation)  # Remove punctuation
dtm <- DocumentTermMatrix(corpus)  # Create a Document-Term Matrix
dtm_matrix <- as.matrix(dtm)  # Convert DTM to a matrix
dim(dtm_matrix)
set.seed(123)  # Makes the result repeatable
trainIndex <- createDataPartition(data$Label, p = 0.8, list = FALSE)  # Split data (80% for training)
trainData <- dtm_matrix[trainIndex, ]  # Training data
testData <- dtm_matrix[-trainIndex, ]  # Testing data
trainLabels <- data$Label[trainIndex]  # Training labels
testLabels <- data$Label[-trainIndex]  # Testing labels
colnames(data)
set.seed(123)  # Makes the result repeatable
set.seed(123)  # Makes the result repeatable
# Use the 'clickbait' column as the labels
trainIndex <- createDataPartition(data$clickbait, p = 0.8, list = FALSE)  # Split data (80% for training)
# Create training and testing sets for the Document-Term Matrix (DTM)
trainData <- dtm_matrix[trainIndex, ]  # Training data (DTM)
testData <- dtm_matrix[-trainIndex, ]  # Testing data (DTM)
# Create training and testing labels using the 'clickbait' column
trainLabels <- data$clickbait[trainIndex]  # Training labels (clickbait column)
testLabels <- data$clickbait[-trainIndex]  # Testing labels (clickbait column)
table(data$clickbait)
>
q()
library("tm")
library(tm)          # For text mining
library(SnowballC)   # For stemming
library(caret)       # For machine learning
library(e1071)       # For Naive Bayes
library(ggplot2)
library(readr)
data<- read_csv(file.choose())
problems()
# Convert the 'Text' column to a corpus (collection of text data)
corpus <- Corpus(VectorSource(data$Text))
# Preprocess the corpus
corpus <- tm_map(corpus, content_transformer(tolower))          # Convert to lowercase
corpus <- tm_map(corpus, removePunctuation)                     # Remove punctuation
corpus <- tm_map(corpus, removeNumbers)                         # Remove numbers
corpus <- tm_map(corpus, removeWords, stopwords("en"))          # Remove stopwords (e.g., "the", "is")
corpus <- tm_map(corpus, stripWhitespace)                       # Remove extra spaces
# Convert the 'Text' column to a corpus (collection of text data)
corpus <- Corpus(VectorSource(data$headline))
# Preprocess the corpus
corpus <- tm_map(corpus, content_transformer(tolower))          # Convert to lowercase
corpus <- tm_map(corpus, removePunctuation)                     # Remove punctuation
corpus <- tm_map(corpus, removeNumbers)                         # Remove numbers
corpus <- tm_map(corpus, removeWords, stopwords("en"))          # Remove stopwords (e.g., "the", "is")
corpus <- tm_map(corpus, stripWhitespace)                       # Remove extra spaces
library(tm)          # For text mining
library(SnowballC)   # For stemming
library(caret)       # For machine learning
library(e1071)       # For Naive Bayes
library(ggplot2)     # For visualization
library(readr)
data<-read_csv(file.choose())
problems()
head()
head(data)
# Convert the 'headline' column to a corpus (collection of text data)
corpus <- Corpus(VectorSource(data$headline))
# Preprocess the corpus
corpus <- tm_map(corpus, content_transformer(tolower))          # Convert to lowercase
corpus <- tm_map(corpus, removePunctuation)                     # Remove punctuation
corpus <- tm_map(corpus, removeNumbers)                         # Remove numbers
corpus <- tm_map(corpus, removeWords, stopwords("en"))          # Remove stopwords (e.g., "the", "is")
corpus <- tm_map(corpus, stripWhitespace)                       # Remove extra spaces
# Check the processed text (first few rows)
inspect(corpus[1:5])  # This will show the first 5 documents after preprocessing
# Create the Document-Term Matrix (DTM)
dtm <- DocumentTermMatrix(corpus)
# Convert DTM to a matrix format
dtm_matrix <- as.matrix(dtm)
# Check the dimensions of the DTM (number of rows and columns)
dim(dtm_matrix)
# Optionally, you can also view the first few rows to get an idea of the data
head(dtm_matrix)
# Set a random seed for reproducibility
set.seed(123)
# Split the data into training (80%) and testing (20%) sets
# Use 'clickbait' as the target variable instead of 'Label'
trainIndex <- createDataPartition(data$clickbait, p = 0.8, list = FALSE)
# Create training and testing datasets from the document-term matrix (dtm_matrix)
trainData <- dtm_matrix[trainIndex, ]
testData <- dtm_matrix[-trainIndex, ]
# Create labels for training and testing sets (clickbait is the target variable)
trainLabels <- data$clickbait[trainIndex]
testLabels <- data$clickbait[-trainIndex]
library(tm)          # For text mining
library(SnowballC)   # For stemming
library(caret)       # For machine learning
library(e1071)       # For Naive Bayes
library(ggplot2)
library(readr)
data<- read_csv(file.choose())
# Convert the 'Text' column to a corpus (collection of text data)
corpus <- Corpus(VectorSource(data$headline))
# Preprocess the corpus
corpus <- tm_map(corpus, content_transformer(tolower))          # Convert to lowercase
corpus <- tm_map(corpus, removePunctuation)                     # Remove punctuation
corpus <- tm_map(corpus, removeNumbers)                         # Remove numbers
corpus <- tm_map(corpus, removeWords, stopwords("en"))          # Remove stopwords (e.g., "the", "is")
corpus <- tm_map(corpus, stripWhitespace)                       # Remove extra spaces
# Create the Document-Term Matrix
dtm <- DocumentTermMatrix(corpus)
# Convert DTM to a matrix format
dtm_matrix <- as.matrix(dtm)
# Check the dimensions of the DTM (number of rows and columns)
dim(dtm_matrix)
# Set a random seed for reproducibility
set.seed(123)
# Split the data into training (80%) and testing (20%) sets
trainIndex <- createDataPartition(data$clickbait, p = 0.8, list = FALSE)
# Create training and testing datasets
trainData <- dtm_matrix[trainIndex, ]
testData <- dtm_matrix[-trainIndex, ]
# Create labels for training and testing sets
trainLabels <- data$clickbait[trainIndex]
testLabels <- data$clickbait[-trainIndex]
# Train a Naive Bayes model using the training data
model <- naiveBayes(trainData, trainLabels)
# Print the model to check the trained details
model
# Make predictions on the testing data
predictions <- predict(model, testData)
# Check the first few predictions
head(predictions)
# Evaluate the model using a confusion matrix
confusionMatrix(predictions, testLabels)
# Ensure both predictions and testLabels are factors with the same levels
predictions <- factor(predictions, levels = c("0", "1"))
testLabels <- factor(testLabels, levels = c("0", "1"))
# Evaluate the model using a confusion matrix
confusionMatrix(predictions, testLabels)
# Create a bar plot to visualize the distribution of labels (Clickbait vs Non-Clickbait)
ggplot(data, aes(x = Label)) +
geom_bar() +
theme_minimal() +
ggtitle("Distribution of Clickbait vs Non-Clickbait")
rlang::last_trace()
# Create a bar plot to visualize the distribution of labels (Clickbait vs Non-Clickbait)
ggplot(data, aes(x = clickbait)) +
geom_bar() +
theme_minimal() +
ggtitle("Distribution of Clickbait vs Non-Clickbait")
# Train an SVM model
svm_model <- svm(trainData, as.factor(trainLabels))
# Make predictions with the SVM model
svm_predictions <- predict(svm_model, testData)
# Evaluate the SVM model
confusionMatrix(svm_predictions, testLabels)
# Create a bar plot to visualize the distribution of labels (Clickbait vs Non-Clickbait)
ggplot(data, aes(x = clickbait)) +
geom_bar() +
theme_minimal() +
ggtitle("Distribution of Clickbait vs Non-Clickbait")
gc()
# Visualize the Results
ggplot(data, aes(x = clickbait)) +        # Create a bar plot to visualize the distribution of labels (Clickbait vs Non-Clickbait)
geom_bar() +
theme_minimal() +
ggtitle("Distribution of Clickbait vs Non-Clickbait")
# Install the required packages
install.packages(c("tm", "SnowballC", "caret", "e1071","readr", "ggplot2"))
# Load the libraries
library(tm)          # For text mining
# Install the required packages
install.packages(c("tm", "SnowballC", "caret", "e1071","readr", "ggplot2"))
# Load the libraries
library(tm)          # For text mining
library(SnowballC)   # For stemming
library(caret)       # For machine learning
library(e1071)       # For Naive Bayes
library(ggplot2)     # For visualization
library(readr)
data <- read_csv(file.choose()) # Load the dataset
head(data)                      # Check the first few rows of the data
# Convert the 'Headline' column to a corpus (collection of text data)
corpus <- Corpus(VectorSource(data$headline)) #In place of headline use name of the column which has text as data
# Preprocess the corpus
corpus <- tm_map(corpus, content_transformer(tolower))          # Convert to lowercase
corpus <- tm_map(corpus, removePunctuation)                     # Remove punctuation
corpus <- tm_map(corpus, removeNumbers)                         # Remove numbers
corpus <- tm_map(corpus, removeWords, stopwords("en"))          # Remove stopwords (e.g., "the", "is")
corpus <- tm_map(corpus, stripWhitespace)                       # Remove extra spaces
#Viewing the corpus
inspect(corpus[1:5]) # View the first 5 documents in the corpus
corpus              # View the entire corpus (not recommended for large corpora)
corpus_df <- data.frame(text = sapply(corpus, content)) # View the corpus into a data frame
#corpus_df <- data.frame(text = sapply(corpus, content)) # View the corpus into a data frame
head(corpus_df)   # View the first few rows
corpus              # View the entire corpus (not recommended for large corpora)
# Create the Document-Term Matrix
dtm <- DocumentTermMatrix(corpus)
dtm_matrix <- as.matrix(dtm)     # Convert DTM to a matrix format
dim(dtm_matrix)                 # Check the dimensions of the DTM (number of rows and columns)
head(dtm_matrix)                #view dtm matrx
summary(dtm)
set.seed(123) # Set a random seed for reproducibility
trainIndex <- createDataPartition(data$clickbait, p = 0.8, list = FALSE) # Split the data into training (80%) and testing (20%) sets
trainData <- dtm_matrix[trainIndex, ]
testData <- dtm_matrix[-trainIndex, ]# Create training and testing datasets
trainLabels <- data$clickbait[trainIndex]
testLabels <- data$clickbait[-trainIndex]# Create labels for training and testing sets
model <- naiveBayes(trainData, trainLabels) # Train a Naive Bayes model using the training data
model    # Print the model to check the trained details
predictions <- predict(model, testData)
predictions <- factor(predictions, levels = c("0", "1")) # Ensure both predictions and testLabels are factors with the same levels
testLabels <- factor(testLabels, levels = c("0", "1")) # Ensure both predictions and testLabels are factors with the same levels
head(predictions) # Check the first few predictions
# Evaluate the model using a confusion matrix
confusionMatrix(predictions, testLabels)
# Visualize the Results
ggplot(data, aes(x = clickbait)) +        # Create a bar plot to visualize the distribution of labels (Clickbait vs Non-Clickbait)
geom_bar() +
theme_minimal() +
ggtitle("Distribution of Clickbait vs Non-Clickbait")
save.image("~/Clickbait_Detection_environment_data.RData")
savehistory("~/Clickbait_Detection_History_data.Rhistory")
# MIT License
#
# Copyright (c) [2024] [Prakash Kumar]
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following condition:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
# Install the required packages
#install.packages(c("tm", "SnowballC", "caret", "e1071","readr", "ggplot2"))
# Load the libraries
library(tm)          # For text mining
library(SnowballC)   # For stemming
library(caret)       # For machine learning
library(e1071)       # For Naive Bayes
library(ggplot2)     # For visualization
library(readr)
data <- read_csv(file.choose()) # Load the dataset
head(data)                      # Check the first few rows of the data
# Convert the 'Headline' column to a corpus (collection of text data)
corpus <- Corpus(VectorSource(data$headline)) #In place of headline use name of the column which has text as data
# Preprocess the corpus
corpus <- tm_map(corpus, content_transformer(tolower))          # Convert to lowercase
corpus <- tm_map(corpus, removePunctuation)                     # Remove punctuation
corpus <- tm_map(corpus, removeNumbers)                         # Remove numbers
corpus <- tm_map(corpus, removeWords, stopwords("en"))          # Remove stopwords (e.g., "the", "is")
corpus <- tm_map(corpus, stripWhitespace)                       # Remove extra spaces
#Viewing the corpus
inspect(corpus[1:5]) # View the first 5 documents in the corpus
corpus              # View the entire corpus (not recommended for large corpora)
#corpus_df <- data.frame(text = sapply(corpus, content)) # View the corpus into a data frame
#head(corpus_df)   # View the first few rows
# Create the Document-Term Matrix
dtm <- DocumentTermMatrix(corpus)
dtm_matrix <- as.matrix(dtm)     # Convert DTM to a matrix format
dim(dtm_matrix)                 # Check the dimensions of the DTM (number of rows and columns)
head(dtm_matrix)                #view dtm matrx
summary(dtm)
# Load the libraries
library(tm)          # For text mining
# MIT License
#
# Copyright (c) [2024] [Prakash Kumar]
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following condition:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
# Install the required packages
#install.packages(c("tm", "SnowballC", "caret", "e1071","readr", "ggplot2"))
# Load the libraries
library(tm)          # For text mining
library(SnowballC)   # For stemming
library(caret)       # For machine learning
library(e1071)       # For Naive Bayes
library(ggplot2)     # For visualization
library(readr)
data <- read_csv(file.choose()) # Load the dataset
head(data)                      # Check the first few rows of the data
# Convert the 'Headline' column to a corpus (collection of text data)
corpus <- Corpus(VectorSource(data$headline)) #In place of headline use name of the column which has text as data
# Preprocess the corpus
corpus <- tm_map(corpus, content_transformer(tolower))          # Convert to lowercase
corpus <- tm_map(corpus, removePunctuation)                     # Remove punctuation
corpus <- tm_map(corpus, removeNumbers)                         # Remove numbers
corpus <- tm_map(corpus, removeWords, stopwords("en"))          # Remove stopwords (e.g., "the", "is")
corpus <- tm_map(corpus, stripWhitespace)                       # Remove extra spaces
#Viewing the corpus
inspect(corpus[1:5]) # View the first 5 documents in the corpus
corpus              # View the entire corpus (not recommended for large corpora)
#corpus_df <- data.frame(text = sapply(corpus, content)) # View the corpus into a data frame
#head(corpus_df)   # View the first few rows
# Create the Document-Term Matrix
dtm <- DocumentTermMatrix(corpus)
dtm_matrix <- as.matrix(dtm)     # Convert DTM to a matrix format
dim(dtm_matrix)                 # Check the dimensions of the DTM (number of rows and columns)
head(dtm_matrix)                #view dtm matrx
#summary(dtm)
#Split Data into Training and Testing Sets
set.seed(123) # Set a random seed for reproducibility
trainIndex <- createDataPartition(data$clickbait, p = 0.8, list = FALSE) # Split the data into training (80%) and testing (20%) sets
trainData <- dtm_matrix[trainIndex, ]
testData <- dtm_matrix[-trainIndex, ]# Create training and testing datasets
trainLabels <- data$clickbait[trainIndex]
testLabels <- data$clickbait[-trainIndex]# Create labels for training and testing sets
# Train the Naive Bayes Model
model <- naiveBayes(trainData, trainLabels) # Train a Naive Bayes model using the training data
model    # Print the model to check the trained details
# Make predictions on the testing data
predictions <- predict(model, testData)
predictions <- factor(predictions, levels = c("0", "1")) # Ensure both predictions and testLabels are factors with the same levels
testLabels <- factor(testLabels, levels = c("0", "1")) # Ensure both predictions and testLabels are factors with the same levels
head(predictions) # Check the first few predictions
# Evaluate the model using a confusion matrix
confusionMatrix(predictions, testLabels)
# Visualize the Results
ggplot(data, aes(x = clickbait)) +        # Create a bar plot to visualize the distribution of labels (Clickbait vs Non-Clickbait)
geom_bar() +
theme_minimal() +
ggtitle("Distribution of Clickbait vs Non-Clickbait")
